{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a2ee85-02e8-4607-839a-80b7ae69b10b",
   "metadata": {},
   "source": [
    "权重衰减是减轻过拟合的一种常用方法，等价于L2范数正则化  \n",
    "具体方法是引入L2范数惩罚项，主要是惩罚绝对值较大的参数从而限制模型  \n",
    "以下是一个权重衰减从零实现缓解过拟合的实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d7bf3b-4c65-4a00-955d-2fecccbde6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里用了一个高维线性回归来模拟过拟合的情况\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import d2lzh_pytorch as d2l\n",
    "n_train,n_test,num_inputs = 20,100,200\n",
    "#训练数据的数量和测试数据的数量\n",
    "true_w,true_b = torch.ones(num_inputs,1)*0.01,0.05\n",
    "features = torch.randn((n_train+n_test,num_inputs))\n",
    "labels = torch.matmul(features,true_w)+true_b\n",
    "labels = torch.tensor(np.random.normal(0,0.01,size = labels.size()),dtype = torch.float)\n",
    "train_features,test_features = features[:n_train,:],features[n_train:,:]\n",
    "train_labels,test_labels = labels[:n_train],labels[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebdbc124-4cbf-49a9-a88e-0c19e0aee51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化模型参数\n",
    "def init_params():\n",
    "    w = torch.randn((num_inputs,1),requires_grad = True)\n",
    "    b = torch.zeros(1,requires_grad= True)\n",
    "    return [w,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f2c506-5ce8-4631-a89d-13b330bbe112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义L2范数惩罚项\n",
    "def l2_penalty(w):\n",
    "    return (w**2).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661d3a2c-2991-41d4-bd0a-3959482221fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练和测试\n",
    "batch_size,num_epochs,lr = 1,100,0.003\n",
    "net = d2l.linreg\n",
    "loss = d2l.squared_loss\n",
    "dataset = torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "train_iter = torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "def fit_and_plot(lambd):\n",
    "    w,b = init_params()\n",
    "    train_ls,test_ls=[],[]\n",
    "    for _ in range(num_epochs):\n",
    "        for X,y in train_iter:\n",
    "            l = loss(net(X,w,b),y)+lambd*l2_penalty(w)\n",
    "            l = l.sum()\n",
    "            if w.grad is not None:\n",
    "                w.grad.data.zero_()\n",
    "                b.grad.data.zero_()\n",
    "            l.backward()\n",
    "            d2l.sgd([w,b],lr,batch_size)\n",
    "        train_ls.append(loss(net(train_features,w,b),train_labels).mean())\n",
    "        test_ls.append(loss(net(test_features,w,b),test_labels).mean())\n",
    "    d2l.semilogy(range(1,num_epochs+1),train_ls,'epochs','loss',\n",
    "                 range(1,num_epochs+1),test_ls,['train','test'])\n",
    "    print('L2 norm of w:',w.norm().item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "603ea59e-ffff-4a00-9b32-d27aed1c4d95",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'd2lzh_pytorch' has no attribute 'semilogy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#如果lambd为0，就是没有使用权重衰减\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfit_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m, in \u001b[0;36mfit_and_plot\u001b[1;34m(lambd)\u001b[0m\n\u001b[0;32m     19\u001b[0m     train_ls\u001b[38;5;241m.\u001b[39mappend(loss(net(train_features,w,b),train_labels)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     20\u001b[0m     test_ls\u001b[38;5;241m.\u001b[39mappend(loss(net(test_features,w,b),test_labels)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m---> 21\u001b[0m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemilogy\u001b[49m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),train_ls,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m              \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),test_ls,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2 norm of w:\u001b[39m\u001b[38;5;124m'\u001b[39m,w\u001b[38;5;241m.\u001b[39mnorm()\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'd2lzh_pytorch' has no attribute 'semilogy'"
     ]
    }
   ],
   "source": [
    "#如果lambd为0，就是没有使用权重衰减\n",
    "fit_and_plot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840916a-4730-47e8-a52f-b5f43f6cd84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
