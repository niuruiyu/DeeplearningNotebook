{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10976cbf-cf72-4cf7-abcc-35a207c3d976",
   "metadata": {},
   "source": [
    "丢弃法就是dropout，这里主要是inverted dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2534073d-a621-46c8-8bea-3ed252961aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从零开始实现\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import d2lzh_pytorch as d2l\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046d731d-5671-468c-a2dd-78baa7ce23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(X,drop_prob):#X是输入的张量，一般是神经网络层（like全连接层的输出）用drop——prob来做丢弃概率\n",
    "    X=X.float()#将张量转换为float类型,确保之后的计算类型一致\n",
    "    assert 0<=drop_prob<=1#断言检查，确保概率0-1，否则报错\n",
    "    keep_prob=1-drop_prob#保留概率\n",
    "    if keep_prob==0:#如果全部都不保留\n",
    "        return torch.zeros_like(X)#直接返回与X相同形状的全零张量\n",
    "    mask = (torch.rand(X.shape)<keep_prob).float()#掩码操作，生成一个torch（服从0，1分布）\n",
    "    #根据keep_prob概率进行保留（要保留的地方是true，不保留的地方是false，在转换为float的格式（数字）\n",
    "    return mask*X/keep_prob#不保留的地方地方mask=0，保留的地方对元素进行缩放（保持输入的总期望不变，确保数据分布不会变化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851f2022-e8a9-4671-b974-82217a1418d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.2500,  2.5000,  3.7500,  5.0000,  0.0000,  7.5000,  8.7500],\n",
       "        [10.0000,  0.0000, 12.5000, 13.7500,  0.0000, 16.2500, 17.5000, 18.7500]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试一下这个dropout\n",
    "x =torch.arange(16).view(2,8)\n",
    "dropout(x,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d325a2-bb9b-42c6-b888-7dcfb214e4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.,  4.,  6.,  8., 10.,  0., 14.],\n",
       "        [ 0.,  0.,  0., 22., 24., 26.,  0., 30.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(x,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33ad0d9-cc92-460b-975f-b4eb004dc5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(x,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4905b267-9ada-4fed-bcd3-130ddd36c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型参数\n",
    "num_inputs,num_outputs,num_hiddens1,num_hiddens2 = 784,10,256,256\n",
    "w1 = torch.tensor(np.random.normal(0,0.01,size = (num_inputs,num_hiddens1)),dtype = torch.float,requires_grad=True)\n",
    "b1 = torch.zeros(num_hiddens1,requires_grad= True)\n",
    "w2 = torch.tensor(np.random.normal(0,0.01,size = (num_hiddens1,num_hiddens2)),dtype = torch.float,requires_grad=True)\n",
    "b2 = torch.zeros(num_hiddens2,requires_grad=True)\n",
    "w3 = torch.tensor(np.random.normal(0,0.01,size = (num_hiddens2,num_outputs)),dtype = torch.float,requires_grad= True)\n",
    "b3 = torch.zeros(num_outputs,requires_grad= True)\n",
    "params = [w1,b1,w2,b2,w3,b3]\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c42d85-643c-4fc9-815d-c00769c4a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "drop_prob1,drop_prob2 = 0.2,0.5\n",
    "def net(X,is_training = True):\n",
    "    X = X.view(-1,num_inputs)\n",
    "    H1 = (torch.matmul(X,w1)+b1).relu()\n",
    "    if is_training:\n",
    "        H1 = dropout(H1,drop_prob1)\n",
    "    H2 = (torch.matmul(H1,w2)+b2).relu()\n",
    "    if is_training:\n",
    "        H2 = dropout(H2,drop_prob2)\n",
    "    Y = torch.matmul(H2,w3)+b3\n",
    "    return Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46274f41-e35f-4473-b192-d265e19ce229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改一下计算精度的函数,这个函数在D2L中修改\n",
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n=0.0,0\n",
    "    for X,y in data_iter:\n",
    "        if isinstance(net,torch.nn.Module):#判断net是否是nn.module的派生类\n",
    "            net.eval()#评估模式，关闭dropout\n",
    "            accs_sum+=(net(X).argmax(dim=1)==y).float().sum().item()\n",
    "            net.train()#改回训练模式\n",
    "        else:#如果是自定义的模型\n",
    "            if('is_training' in net.__code__.co_varnames):#如果有is_training这个参数\n",
    "                #将这个参数设为F\n",
    "                acc_sum+=(net(X,is_training=False).argmax(dim=1)==y).float().sum().item()\n",
    "            else:\n",
    "                acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item()\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1722b99d-4c16-47fc-b34a-43eb5cfdb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "num_epochs,lr,batch_size = 5,100.0,256\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "train_data = torchvision.datasets.FashionMNIST(root='~/DataSets/FashionMNIST',train = True,download=True,transform = transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST(root='~/DataSets/FashionMNIST',train=False,download = True,transform = transforms.ToTensor())\n",
    "num_workers =4\n",
    "train_iter = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a17d9bc-7cb7-4d81-9adb-6188779596c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Lenovo\\source\\githubrepository\\DeeplearingNotebook\\DiveintoDL_pytorch\\d2lzh_pytorch.py:91: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  print('epoch %d,loss%.4f,train acc %.3f,test acc %.3f'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss0.0047,train acc 0.539,test acc 0.715\n",
      "epoch 2,loss0.0023,train acc 0.780,test acc 0.796\n",
      "epoch 3,loss0.0019,train acc 0.823,test acc 0.826\n",
      "epoch 4,loss0.0017,train acc 0.839,test acc 0.846\n",
      "epoch 5,loss0.0016,train acc 0.849,test acc 0.787\n"
     ]
    }
   ],
   "source": [
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f76bbdca-7bf1-4571-bce4-e92e33262660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#简洁实现\n",
    "net = nn.Sequential(\n",
    "    d2l.FlattenLayer(),\n",
    "    nn.Linear(num_inputs,num_hiddens1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob1),\n",
    "    nn.Linear(num_hiddens1,num_hiddens2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob2),\n",
    "    nn.Linear(num_hiddens2,num_outputs)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dedaa13-07f4-4364-940a-4c5d4a6119bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    nn.init.normal_(param,mean=0,std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0814f9ba-f8d5-451c-b408-b9634aa2cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Lenovo\\source\\githubrepository\\DeeplearingNotebook\\DiveintoDL_pytorch\\d2lzh_pytorch.py:91: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  print('epoch %d,loss%.4f,train acc %.3f,test acc %.3f'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss0.0046,train acc 0.542,test acc 0.748\n",
      "epoch 2,loss0.0023,train acc 0.783,test acc 0.746\n",
      "epoch 3,loss0.0019,train acc 0.819,test acc 0.782\n",
      "epoch 4,loss0.0018,train acc 0.834,test acc 0.823\n",
      "epoch 5,loss0.0017,train acc 0.845,test acc 0.843\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.5)\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,None,None,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4d6a7-5ed4-4ed8-9497-86cb281e5c6f",
   "metadata": {},
   "source": [
    "dropout只有在训练模式时才能使用，所以在上面的accracy计算中（这个函数只用来计算测试集的acc）  \n",
    "进行net.eval()的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24229f9b-410e-435c-9379-abea94dfa37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
