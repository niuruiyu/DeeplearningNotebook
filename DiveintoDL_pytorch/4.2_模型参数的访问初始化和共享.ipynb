{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9b6090-3723-4c2f-896a-389bb90ebb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#先定义一个含有单层隐藏层的多层感知机\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4,3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3,1)\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddf3834-64ae-4337-ac83-7b0263e32f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(2,4)\n",
    "Y = net(X).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633fb58d-7486-4dbb-bc57-4928ec4b22bb",
   "metadata": {},
   "source": [
    "访问模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f366b0a0-e819-41b6-bd18-19db45674979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "0.weight torch.Size([3, 4])\n",
      "0.bias torch.Size([3])\n",
      "2.weight torch.Size([1, 3])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#使用Module类的parameters()或mnamed_parameters方法\n",
    "#named_parameters方法以迭代器的形式返回，除了返回tensor，还会返回参数的名称\n",
    "print(type(net.named_parameters()))\n",
    "for name,param in net.named_parameters():\n",
    "    print(name,param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cdb47d-9bb9-4878-9b35-3786b9b4af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([3, 4]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias torch.Size([3]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "#d对于sequential的网络，可以用[]索引来访问俩民的任意一层的参数\n",
    "for name,param in net[0].named_parameters():\n",
    "    print(name,param.size(),type(param))\n",
    "#返回的type是torch.nn.parameter.Paramete，是tensor的子类\n",
    "#如果一个tensor是parameters，那么它会自动被添加到模型的参数列表里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5450b4a4-0f77-4421-b953-e1bb05cdc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(MyModel,self).__init__(**kwargs)\n",
    "        self.weight1 = nn.Parameter(torch.rand(20,20))\n",
    "        self.weight2 = torch.rand(20,20)\n",
    "    def forward(self,x):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad6c65b-5db1-48b1-a065-dab93f7ababd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight1 torch.Size([20, 20]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "n = MyModel()\n",
    "for name,param in n.named_parameters():\n",
    "    print(name,param.size(),type(param))\n",
    "#根据上面，weight1是Parameter类，那么会自动被添加到参数列表里，所以这里输出，只有weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a640f75c-436b-4a7b-890b-0f4b87579b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "#Parameter是tensor，所以tensor的特性他都有\n",
    "#这里用parameters来得到参数，所以parameters()方法是得到了list，可以用索引的到特定的参数\n",
    "weight_0 = list(net[0].parameters())[0]\n",
    "print(weight_0.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf1d2a-d782-4201-b7f4-dbce3c47b23d",
   "metadata": {},
   "source": [
    "初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a792c870-9421-4db0-aa94-bae657e1830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[ 0.0189,  0.0113,  0.0122,  0.0175],\n",
      "        [ 0.0170,  0.0082, -0.0108, -0.0151],\n",
      "        [-0.0031, -0.0096,  0.0076,  0.0052]])\n",
      "2.weight tensor([[ 0.0107, -0.0045,  0.0040]])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.normal_(param,mean=0,std=0.01)\n",
    "        print(name ,param.data)\n",
    "#正态分布初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b3c34f-8061-4641-88ae-94ea02553dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.bias tensor([0., 0., 0.])\n",
      "2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "#常数初始化参数\n",
    "for name,param in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        init.constant_(param,val = 0)\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74712ec8-476d-406d-b81a-ab8eabc811cd",
   "metadata": {},
   "source": [
    "自定义初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e7e4693-54ce-4300-b66b-bfab2625dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#有些方法没有在init模块中给出，就需要实现一个初始化方法\n",
    "#torch.nn.init.normal_的实现\n",
    "def normal_(tensor,mean=0,std=1):\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(mean,std)\n",
    "#本质是一个inpalce改变tensor值的函数，不计梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5acce9c0-5a96-4c5f-90a4-20ca64cfa432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[ 0.0000,  8.6678,  9.9834, -8.5890],\n",
      "        [-8.2359, -6.9382,  9.0086,  0.0000],\n",
      "        [-7.4985,  9.3658, -0.0000,  8.1228]])\n",
      "2.weight tensor([[0.0000, 5.3146, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "#实现一个自定义的初始化方法\n",
    "#这里让权重有一半的概率初始化为0，另一半概率初始化为-10，-5和5，10两个区间里均匀分布的随机数\n",
    "def init_weight_(tensor):\n",
    "    with torch.no_grad():\n",
    "        tensor.uniform_(-10,10)#对tensor进行原地修改，初始化为区间-10到10内的随机数\n",
    "        tensor *=(tensor.abs()>=5).float()#绝对值小于5的数被初始化为0\n",
    "for name,param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init_weight_(param)\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0bbab2a-b217-42e6-9cd8-08839a977a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.bias tensor([1., 1., 1.])\n",
      "2.bias tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "#还可以通过直接改变参数data的值（因为改data不影响梯度\n",
    "for name,param in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        param.data+=1\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd3b8c-c5c9-4c99-a461-e50ebadbff9d",
   "metadata": {},
   "source": [
    "共享模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ac14abd-6466-4e44-9dd5-a87426b859ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=False)\n",
      "  (1): Linear(in_features=1, out_features=1, bias=False)\n",
      ")\n",
      "0.weight tensor([[3.]])\n"
     ]
    }
   ],
   "source": [
    "#如果传入sequtential的模块是同一个module实例的话，那么参数也是共享的\n",
    "linear = nn.Linear(1,1,bias = False)\n",
    "net = nn.Sequential(linear,linear)\n",
    "print(net)\n",
    "for name,param in net.named_parameters():\n",
    "    init.constant_(param,3)\n",
    "    print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9db8f61-c086-47de-a34a-30eed3b5c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#在内存中这两个先行曾是一个对象\n",
    "print(id(net[0])==id(net[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "112a1907-be4d-4042-a4d5-0e16b546e220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#模型参数种包含梯度，所以在反向传播计算时，哲别共享的参数的梯度也是累加的\n",
    "x = torch.ones(1,1)\n",
    "y = net(x).sum()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6c4a9bf-130b-43ba-baf2-2cb1f1e1342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y.backward()\n",
    "print(net[0].weight.grad)#单次梯度时3，两次就是6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c6ccb-2f8a-4046-a31f-1e9df8f6a320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
